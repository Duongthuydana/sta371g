\documentclass{beamer}
\usepackage{../371g-slides}
\title{Multiple Regression 2}
\subtitle{Lecture 13}
\author{STA 371G}

\begin{document}
  <<setup, include=F, cache=F>>=
  opts_knit$set(global.par=T)
  knit_hooks$set(crop=hook_pdfcrop)
  opts_chunk$set(dev='tikz', external=F, fig.path='/tmp/figures/', comment=NA, fig.width=4, fig.height=3, crop=T, sanitize=T, prompt=T, tidy=F)
  knit_theme$set('camo')
  @
  <<include=F, cache=F>>=
  par(fg='#fefefe', col.axis='#fefefe', col.lab='#fefefe', col.main="#fefefe", mar=c(5.1, 4.1, 1.1, 2.1))
  @
  <<include=F>>=
  library(readr)
  library(car)
  boston <- read_csv("../../data/boston.csv")

  @

  \frame{\maketitle}

  % Show outline at beginning of each section
  \AtBeginSection[]{
    \begin{frame}<beamer>
      \tableofcontents[currentsection]
    \end{frame}
  }

  %%%%%%% Slides start here %%%%%%%

  \begin{darkframes}
    \begin{frame}{Midterm 1 results}
      \begin{itemize}[<+->]
        \item Scores and feedback will be available in Canvas/Quest later today or tomorrow
        \item Approximately: mean = 74\%, median = 75\%, SD = 15\%
        \item Since this was our first exam using Quest, you can retake the exam and get up to half credit back starting Thursday 5 PM
        \item Example: if you got a 60\%, and you get a 100\% on the retake, your new Midterm 1 score will be 80\%
        \item Your retake submission is due one week later (Thursday, March 8 at 5 PM)
      \end{itemize}
      \note{Start with an LC Q2 to review}
    \end{frame}

    \begin{frame}[fragile]{Predicting median house prices in Boston}
      <<>>=
      model <- lm(MEDV ~ CRIME + ZONE + NOX + ROOM + DIST
                   + RADIAL + TAX + PTRATIO + LSTAT,
                   data=boston)
      @
      \begin{columns}[onlytextwidth]
        \column{.5\textwidth}
          \begin{itemize}
            \item MEDV: Median Price (response)
            \item CRIME: Per capita crime rate
            \item ZONE: Proportion of large lots
            \item NOX: Nitrogen Oxide concentration
            \item DIST: Distance to employment centers
          \end{itemize}
        \column{.5\textwidth}
          \begin{itemize}
            \item ROOM: Average \# of rooms
            \item RADIAL: Accessibility to highways
            \item TAX: Tax rate (per \$10K)
            \item PTRATIO: Pupil-to-teacher ratio
            \item LSTAT: Proportion of ``lower status''
            %  proportion of adults without some high school education or that are classified as laborers
          \end{itemize}
      \end{columns}
    \end{frame}



    \begin{frame}[fragile]{Overall Null Hypothesis}
      Is our model useful? Let's look at $R^2$:
      <<>>=
      summary(model)$r.squared
      @
      \pause
      Can we be confident that our model will generalize to the \alert{population}?  \pause

      \bigskip

      $H_0: \beta_1=\beta_2=\beta_3=\beta_4=\beta_5=\beta_6=\beta_7=\beta_8=\beta_9=0$ (Data explains nothing!) \pause

      $H_A: \beta_i \neq 0$ for some $i$ (At least one predictor is useful) \pause

      or

      $H_0: R^2=0 \qquad H_A: R^2>0$
    \end{frame}



   \begin{frame}[fragile]{Overall Null Hypothesis}
      Check the $p$-value in the summary:
      \begin{center}
        \includegraphics[width=4in]{r_sq_pval} \\
      \end{center}
      So we can reject the overall null hypothesis! \pause
      \bigskip
      ($R^2$ was already too big to suspect that it was actually zero in the population---and we already knew some predictors are statistically significant!)
    \end{frame}



    \begin{frame}[fragile]{How good are our predictions?}
      Let's plot the residuals (the discrepancies between the predicted and actual home prices). \pause

      <<fig.height=2>>=
      hist(resid(model), col='green',
        main='', xlab='Residuals ($)', ylab='Frequency')
      @


    \end{frame}


    \begin{frame}[fragile]{How good are our predictions?}
      Let's look at the mean of the residuals: \pause
      <<>>=
      mean(resid(model))
      @
      It will be always zero since regression minimizes the sum of squared residuals! \pause
      Now let's look at the standard deviation: \pause

      <<>>=
      sd(resid(model))
      @
      \pause
      Since the residuals are roughly normal, by the 2 SD rule about 95\% of the time predictions will be off by less than \$\Sexpr{format(round(2*sd(resid(model))), scientific=F)}.
    \end{frame}


    \begin{frame}[fragile]{How good are our predictions?}
      The residual standard error provides a \alert{similar} measure directly from the summary of the regression:

      \note{Emphasize that standard error and what we get with sd() is similar, but not exactly the same.
           sd() estimates the population std dev, standard error is obtained by dividing SS by the num. deg. of freedom. }

      <<>>=
      summary(model)$sigma
      @
      \quad \pause
      \begin{center}
        \includegraphics[width=4in]{std_err} \\
      \end{center}

    \end{frame}



    \begin{frame}{Again: regression assumptions}
      Remember the big four:
      \begin{enumerate}
        \item \alert{The residuals are independent.}
        \item $Y$ is a linear function of $X$s (except for the errors).
        \item The residuals are normally distributed.
        \item The variance of $Y$ is the same for any value of $X$s (``homoscedasticity'').

      \end{enumerate}
    \end{frame}


    \begin{frame}[fragile]{Assumption 1: Independence}
      Independence: No correlation between residuals \pause --- we have to think this through; can't use a plot here.
      \pause
      Remember that we want the \alert{cases} to be independent, not the \alert{variables}. We very much hope that $Y$ will be dependent on the $X$'s (otherwise, why are we trying to predict $Y$ based on the $X$'s?).
    \end{frame}





    \begin{frame}{Again: regression assumptions}
      Remember the big four:
      \begin{enumerate}
        \item The residuals are independent. \greencheckmark
        \item \alert{$Y$ is a linear function of $X$s (except for the errors).}
        \item The residuals are normally distributed.
        \item The variance of $Y$ is the same for any value of $X$s (``homoscedasticity'').
      \end{enumerate}
    \end{frame}



    \begin{frame}[fragile]{Assumption 2: Linearity}
      Plot the residuals vs the \alert{predicted Y-values} and ensure there is no trend:
      <<fig.height=2>>=
      plot(predict(model), resid(model), col="green",
        xlab="Predicted values", ylab="Residuals")
      @
    \end{frame}


    \begin{frame}{Again: regression assumptions}
      Remember the big four:
      \begin{enumerate}
        \item The residuals are independent. \greencheckmark
        \item $Y$ is a linear function of $X$s (except for the errors). \greencheckmark
        \item \alert{The residuals are normally distributed.}
        \item The variance of $Y$ is the same for any value of $X$s (``homoscedasticity'').
      \end{enumerate}
    \end{frame}



    \begin{frame}[fragile]{Assumption 3: Normally distributed residuals}
      Ensure that the Q-Q plot shows a (roughly) straight line:
      <<fig.height=2>>=
      qqnorm(resid(model), main='')
      @
    \end{frame}


    \begin{frame}{Again: regression assumptions}
      Remember the big four:
      \begin{enumerate}
        \item The residuals are independent. \greencheckmark
        \item $Y$ is a linear function of $X$s (except for the errors). \greencheckmark
        \item The residuals are normally distributed. \greencheckmark
        \item \alert{The variance of $Y$ is the same for any value of $X$s (``homoscedasticity'').}
      \end{enumerate}
    \end{frame}


    \begin{frame}[fragile]{Assumption 4: The variance of $Y$ is the same across}
      Look for a (roughly) constant vertical ``thickness'':
      <<fig.height=2>>=
      plot(predict(model), resid(model), col="green",
        xlab="Predicted values", ylab="Residuals")
      @
    \end{frame}

    \begin{frame}{Again: regression assumptions}
      Remember the big four:
      \begin{enumerate}
        \item The residuals are independent. \greencheckmark
        \item $Y$ is a linear function of $X$s (except for the errors). \greencheckmark
        \item The residuals are normally distributed. \greencheckmark
        \item The variance of $Y$ is the same for any value of $X$s (``homoscedasticity'').  \greencheckmark
      \end{enumerate}
      \pause
      \alert{w00t w00t!} \pause This model meets the assumptions for regression, so it is safe to interpret $p$-values and confidence intervals.
      \lc
    \end{frame}


    \begin{frame}[fragile]{We have a model. Now what?}
      Let's make some predictions.
    \end{frame}


    \begin{frame}[fragile]{Making predictions}
      The regression model estimates the coefficients of the predictors:
      \fontsize{9}{9}\selectfont
      <<>>=
      round(summary(model)$coefficients, 4)
      @

    \end{frame}


    \begin{frame}[fragile]{Making predictions}
      Let's estimate the median house price in a particular district:
      \fontsize{9}{9}\selectfont

      \begin{table}[!b]
        {\carlitoTLF % Use monospaced lining figures
        \begin{tabularx}{\textwidth}{XXrrr}

           $j$ & Predictor  & $\beta_j$   &  $X_j$  & $\beta_j X_j$ \\
          \toprule
            0 & Intercept	&	840.07	&	1	&	840.07  \\
            1 & CRIME	&	-2.57	&	0.03	&	-0.0771  \\
            2 & ZONE	&	0.92	&	10	&	9.2  \\
            3 & NOX	&	-346.93	&	0.5	&	-173.465  \\
            4 & ROOM	&	74.24	&	4	&	296.96  \\
            5 & DIST	&	-31.05	&	5	&	-155.25  \\
            6 & RADIAL	&	6	&	1	&	6  \\
            7 & TAX	&	-0.27	&	300	&	-81  \\
            8 & PTRATIO	&	-19.28	&	15	&	-385.6  \\
            9 & LSTAT	&	-11.07	&	10	&	-110.7  \\
          \bottomrule
             Price &  Estimate 	& 	&		&	342.538   \\


        \end{tabularx}}

      \end{table}

    \end{frame}



    \begin{frame}[fragile]{Making predictions}
      Let R do it for us!

      <<>>=
      predict.lm(model, list(CRIME=0.03, ZONE=10,
                             NOX=0.5,	ROOM=4,
                             DIST=5,	RADIAL=1,
                             TAX=300, PTRATIO=15,
                             LSTAT=10))
      @
      \note{The discrepancy is due to rounding in the previous slide.}

    \end{frame}


    \begin{frame}[fragile]{Model coefficients}
      Suppose there are 420 students and 28 teachers in the disctrict ($\text{PTRATIO}=420/28=15$). \pause

      \bigskip

      The school board is considering hiring 2 more teachers. How would this affect the house prices in the district? \pause

      \bigskip

      The new PTRATIO will be $420/30=14$. \pause

      <<>>=
      predict.lm(model, list(CRIME=0.03, ZONE=10,
                             NOX=0.5,	ROOM=4,
                             DIST=5,	RADIAL=1,
                             TAX=300, PTRATIO=14,
                             LSTAT=10))
      @
    \end{frame}



    \begin{frame}[fragile]{Model coefficients}
      To be able to compansate the new hires, the school district must add \$50 more on your tax bill for every \$10K of your house price. \pause

      \bigskip
      So, the tax rate increases to \$50 per \$10K. How would this affect the median house price?

      \lc

    \end{frame}



    \begin{frame}[fragile]{Confidence intervals}
      We know our predictions are not exactly right.

      Can we come up with some confidence intervals on our predictions? \pause
      \bigskip

      Remember the two kinds of intervals:
      \bigskip

      \begin{tabular}{lp{1in}p{2in}}
        \textbf{Confidence} & Predicting the mean value of $Y$ for a particular  set of $X$ values. & Among all the districts whose predictors are as above, what is the mean value of median house price?  \\
        \textbf{Prediction} & Predicting $Y$ for a single new case. & If Springfield has the predictors above, what is the median house price in Springfield?\\
      \end{tabular}


    \end{frame}



    \begin{frame}[fragile]{Confidence intervals}
      <<>>=
      predict.lm(model, list(CRIME=0.03, ZONE=10,
                             NOX=0.5,	ROOM=4,
                             DIST=5,	RADIAL=1,
                             TAX=350, PTRATIO=14,
                             LSTAT=10),
                             interval = 'confidence')
      @
     \lc
     \end{frame}



     \begin{frame}[fragile]%{Confidence intervals}
        We can also put a confidence interval on a coefficient to estimate the plausible range of its effect.

        \fontsize{9}{9}\selectfont

        <<>>=
        confint(model)
        @

        \fontsize{11}{13}\selectfont

        \pause
        We are 95\% confident that the effect of reducing the pupil/teacher ratio (PTRATIO) by 1 on median house price is between \$14K and \$24K!

        \lc
     \end{frame}



  \end{darkframes}

\end{document}
